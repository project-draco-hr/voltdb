{
  KafkaStreamImporterException probeException=null;
  int correlationId=0;
  OUTER:   for (int attempts=0; attempts < 3; ++attempts) {
    for (    HostAndPort hp : m_brokers) {
      BlockingChannel channel=null;
      try {
        channel=new BlockingChannel(hp.getHost(),hp.getPort(),BlockingChannel.UseDefaultBufferSize(),BlockingChannel.UseDefaultBufferSize(),m_consumerSocketTimeout);
        channel.connect();
        channel.send(new ConsumerMetadataRequest(m_groupId,ConsumerMetadataRequest.CurrentVersion(),correlationId++,CLIENT_ID));
        ConsumerMetadataResponse metadataResponse=ConsumerMetadataResponse.readFrom(channel.receive().buffer());
        if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
          Broker offsetManager=metadataResponse.coordinator();
          m_coordinator=new HostAndPort(offsetManager.host(),offsetManager.port());
          SimpleConsumer consumer=m_offsetManager.getAndSet(new SimpleConsumer(m_coordinator.getHost(),m_coordinator.getPort(),m_consumerSocketTimeout,m_fetchSize,CLIENT_ID));
          info("Offset Coordinator for " + m_topicAndPartition + " is "+ offsetManager);
          closeConsumer(consumer);
          probeException=null;
          consumer=null;
          break OUTER;
        }
        probeException=new KafkaStreamImporterException("Failed to get Offset Coordinator for %s",ErrorMapping.exceptionFor(metadataResponse.errorCode()),m_topicAndPartition);
      }
 catch (      Exception e) {
        probeException=new KafkaStreamImporterException("Failed to get Offset Coordinator for %s",e,m_topicAndPartition);
      }
 finally {
        if (channel != null) {
          channel.disconnect();
        }
      }
    }
    if (probeException != null) {
      warn(probeException,"Failed to query all brokers for the offeset coordinator for " + m_topicAndPartition);
    }
    backoffSleep(attempts + 1);
  }
}
