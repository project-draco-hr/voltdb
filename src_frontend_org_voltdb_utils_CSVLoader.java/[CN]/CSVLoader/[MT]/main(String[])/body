{
  start=System.currentTimeMillis();
  long insertTimeStart=start;
  long insertTimeEnd;
  final CSVConfig cfg=new CSVConfig();
  cfg.parse(CSVLoader.class.getName(),args);
  config=cfg;
  configuration();
  final Tokenizer tokenizer;
  ICsvListReader listReader=null;
  try {
    if (CSVLoader.standin) {
      tokenizer=new Tokenizer(new BufferedReader(new InputStreamReader(System.in)),csvPreference,config.strictquotes,config.escape,config.columnsizelimit,config.skip);
      listReader=new CsvListReader(tokenizer,csvPreference);
    }
 else {
      tokenizer=new Tokenizer(new FileReader(config.file),csvPreference,config.strictquotes,config.escape,config.columnsizelimit,config.skip);
      listReader=new CsvListReader(tokenizer,csvPreference);
    }
  }
 catch (  FileNotFoundException e) {
    m_log.error("CSV file '" + config.file + "' could not be found.");
    System.exit(-1);
  }
  final String[] serverlist=config.servers.split(",");
  final ClientConfig c_config=new ClientConfig(config.user,config.password);
  c_config.setProcedureCallTimeout(0);
  Client csvClient=null;
  try {
    csvClient=CSVLoader.getClient(c_config,serverlist,config.port);
  }
 catch (  Exception e) {
    m_log.error("Error connecting to the servers: " + config.servers);
    close_cleanup();
    System.exit(-1);
  }
  assert(csvClient != null);
  try {
    setupCSVLoader(csvClient);
    CountDownLatch processor_cdl=new CountDownLatch(numProcessors);
    CSVPartitionProcessor.m_processor_cdl=processor_cdl;
    CSVPartitionProcessor.m_colInfo=colInfo;
    CSVPartitionProcessor.m_columnTypes=columnTypes;
    CSVPartitionProcessor.m_insertProcedure=insertProcedure;
    CSVPartitionProcessor.m_isMP=isMP;
    CSVPartitionProcessor.m_config=config;
    CSVPartitionProcessor.m_tableName=config.table;
    List<Thread> spawned=new ArrayList<Thread>(numProcessors);
    CSVLineWithMetaData endOfData=new CSVLineWithMetaData(null,null,-1);
    Map<Integer,BlockingQueue<CSVLineWithMetaData>> lineq=new HashMap<Integer,BlockingQueue<CSVLineWithMetaData>>(numProcessors);
    List<CSVPartitionProcessor> processors=new ArrayList<CSVPartitionProcessor>(numProcessors);
    for (int i=0; i < numProcessors; i++) {
      LinkedBlockingQueue<CSVLineWithMetaData> partitionQueue=new LinkedBlockingQueue<CSVLineWithMetaData>(Integer.MAX_VALUE);
      lineq.put(i,partitionQueue);
      CSVPartitionProcessor processor=new CSVPartitionProcessor(csvClient,i,partitionedColumnIndex,partitionQueue,endOfData);
      processors.add(processor);
      Thread th=new Thread(processor);
      th.setName(processor.m_processorName);
      spawned.add(th);
    }
    CSVFileReader.m_config=config;
    CSVFileReader.m_listReader=listReader;
    CSVFileReader.m_partitionedColumnIndex=partitionedColumnIndex;
    CSVFileReader.m_partitionColumnType=partitionColumnType;
    CSVFileReader.m_typeList=typeList;
    CSVFileReader.m_columnCnt=columnCnt;
    CSVFileReader.m_csvClient=csvClient;
    CSVFileReader.processorQueues=lineq;
    CSVFileReader.m_endOfData=endOfData;
    CSVFileReader.m_processor_cdl=processor_cdl;
    CSVFileReader csvReader=new CSVFileReader();
    Thread th=new Thread(csvReader);
    th.setName("CSVFileReader");
    th.setDaemon(true);
    for (    Thread th2 : spawned) {
      th2.start();
    }
    th.start();
    th.join();
    long readerTime=(csvReader.m_parsingTime) / 1000000;
    insertTimeEnd=System.currentTimeMillis();
    csvClient.drain();
    csvClient.close();
    long insertCount=0;
    for (    CSVPartitionProcessor pp : processors) {
      insertCount+=pp.m_partitionProcessedCount.get();
    }
    long ackCount=CSVPartitionProcessor.m_partitionAcknowledgedCount.get();
    m_log.info("Parsing CSV file took " + readerTime + " milliseconds.");
    m_log.info("Inserting Data took " + ((insertTimeEnd - insertTimeStart) - readerTime) + " milliseconds.");
    m_log.info("Inserted " + insertCount + " and acknowledged "+ ackCount+ " rows (final)");
    produceFiles(ackCount,insertCount);
    close_cleanup();
  }
 catch (  Exception ex) {
    ex.printStackTrace();
  }
}
