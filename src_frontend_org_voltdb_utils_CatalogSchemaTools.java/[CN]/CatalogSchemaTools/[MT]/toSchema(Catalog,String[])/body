{
  StringBuilder[] schemas=new StringBuilder[2];
  StringBuilder schema=new StringBuilder();
  StringBuilder schemaWithBatches;
  schema.append("-- This file was generated by VoltDB version ");
  schema.append(VoltDB.instance().getVersionString());
  SimpleDateFormat sdf=new SimpleDateFormat("yyyy-MM-dd HH:mm:ss z");
  String time=sdf.format(System.currentTimeMillis());
  schema.append(" on: " + time + ".\n");
  schema.append("-- This file represents the current database schema.\n");
  schema.append("-- Use this file as input to reproduce the current database structure in another database instance.\n");
  schema.append("--\n");
  schemaWithBatches=new StringBuilder(schema);
  schemas[0]=schema;
  schemas[1]=schemaWithBatches;
  schemaWithBatches.append("-- This file uses the --inlinebatch feature. Batching processes all of the DDL in a single step\n");
  schemaWithBatches.append("-- dramatically reducing the time required to apply the schema compared to processing each\n");
  schemaWithBatches.append("-- command separately.\n");
  schemaWithBatches.append("--\n");
  append(schemas,"-- If the schema declares Java stored procedures, be sure to load the .jar file\n");
  append(schemas,"-- with the classes before loading the schema. For example:\n");
  append(schemas,"--\n");
  append(schemas,"-- LOAD CLASSES voltdb-procs.jar;\n");
  append(schemas,"-- FILE ddl.sql;\n");
  for (  Cluster cluster : catalog.getClusters()) {
    for (    Database db : cluster.getDatabases()) {
      if (db.getIsactiveactivedred()) {
        append(schemas,String.format("SET %s=%s;\n",DatabaseConfiguration.DR_MODE_NAME,DatabaseConfiguration.ACTIVE_ACTIVE));
      }
      toSchema(schemas,importLines);
      for (      Group grp : db.getGroups()) {
        toSchema(schemas,grp);
      }
      append(schemas,"\n");
      List<Table> viewList=new ArrayList<Table>();
      CatalogMap<Table> tables=db.getTables();
      if (!tables.isEmpty()) {
        schemaWithBatches.append("file -inlinebatch END_OF_BATCH\n");
        for (        Table table : db.getTables()) {
          Object annotation=table.getAnnotation();
          if (annotation != null && ((TableAnnotation)annotation).ddl != null && table.getMaterializer() != null) {
            viewList.add(table);
            continue;
          }
          toSchema(schemas,table,null,CatalogUtil.getExportTargetIfExportTableOrNullOtherwise(db,table));
        }
        for (        Table table : viewList) {
          String viewQuery=((TableAnnotation)table.getAnnotation()).ddl;
          toSchema(schemas,table,viewQuery,CatalogUtil.getExportTargetIfExportTableOrNullOtherwise(db,table));
        }
      }
      CatalogMap<Procedure> procedures=db.getProcedures();
      if (!procedures.isEmpty()) {
        for (        Procedure proc : db.getProcedures()) {
          toSchema(schemas,proc);
        }
      }
      if (!tables.isEmpty()) {
        schemaWithBatches.append("END_OF_BATCH\n");
      }
    }
  }
  if (dumpSchema) {
    String ts=new SimpleDateFormat("MMddHHmmssSSS").format(new Date());
    File f=new File(String.format("/tmp/canonical-%s.sql",ts));
    try {
      FileWriter fw=new FileWriter(f);
      fw.write(schema.toString());
      fw.close();
    }
 catch (    IOException e) {
      e.printStackTrace();
    }
  }
  String[] schemasAsStrings=new String[schemas.length];
  for (int i=0; i < schemas.length; i++) {
    schemasAsStrings[i]=schemas[i].toString();
  }
  return schemasAsStrings;
}
