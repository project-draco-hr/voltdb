{
  final String topic=topicPrefix + "EXPORT_PARTITIONED_TABLE";
  final String topic2=topicPrefix + "EXPORT_PARTITIONED_TABLE2";
  final String doneTopic=topicPrefix + "EXPORT_DONE_TABLE";
  List<Future<Long>> doneFutures=new ArrayList<>();
  Map<String,Integer> topicCountMap=new HashMap<>();
  topicCountMap.put(topic,1);
  Map<String,List<KafkaStream<byte[],byte[]>>> consumerMap=m_kafkaConfig.consumer.createMessageStreams(topicCountMap);
  List<KafkaStream<byte[],byte[]>> streams=consumerMap.get(topic);
  ExecutorService executor=Executors.newFixedThreadPool(streams.size());
  CountDownLatch consumersLatch=new CountDownLatch(streams.size());
  for (  final KafkaStream stream : streams) {
    System.out.println("Creating consumer for " + topic);
    ExportConsumer consumer=new ExportConsumer(stream,false,skinny,consumersLatch);
    executor.submit(consumer);
  }
  Map<String,Integer> topicCountMap2=new HashMap<>();
  topicCountMap2.put(topic2,1);
  Map<String,List<KafkaStream<byte[],byte[]>>> consumerMap2=m_kafkaConfig.consumer2.createMessageStreams(topicCountMap2);
  List<KafkaStream<byte[],byte[]>> streams2=consumerMap2.get(topic2);
  ExecutorService executor2=Executors.newFixedThreadPool(streams2.size());
  CountDownLatch consumersLatch2=new CountDownLatch(streams2.size());
  for (  final KafkaStream stream : streams2) {
    System.out.println("Creating consumer for " + topic2);
    ExportConsumer consumer=new ExportConsumer(stream,false,skinny,consumersLatch2);
    executor2.submit(consumer);
  }
  Map<String,Integer> topicDoneCountMap=new HashMap<String,Integer>();
  topicDoneCountMap.put(doneTopic,1);
  Map<String,List<KafkaStream<byte[],byte[]>>> doneConsumerMap=m_kafkaConfig.doneConsumer.createMessageStreams(topicDoneCountMap);
  List<KafkaStream<byte[],byte[]>> doneStreams=doneConsumerMap.get(doneTopic);
  ExecutorService executord2=Executors.newFixedThreadPool(doneStreams.size());
  CompletionService<Long> ecs=new ExecutorCompletionService<>(executord2);
  CountDownLatch doneLatch=new CountDownLatch(doneStreams.size());
  for (  final KafkaStream stream : doneStreams) {
    System.out.println("Creating consumer for " + doneTopic);
    ExportConsumer consumer=new ExportConsumer(stream,true,true,doneLatch);
    Future<Long> f=ecs.submit(consumer,new Long(0));
    doneFutures.add(f);
  }
  System.out.println("All Consumer Creation Done...Waiting for EOS");
  ecs.take().get();
  System.out.println("Done Consumer Saw EOS...Cancelling rest of the done consumers.");
  for (  Future<Long> f : doneFutures) {
    f.cancel(true);
  }
  System.out.println("Wait for drain of consumers.");
  long cnt=consumedRows.get();
  long wtime=System.currentTimeMillis();
  while (true) {
    Thread.sleep(5000);
    if (cnt != consumedRows.get()) {
      wtime=System.currentTimeMillis();
      System.out.println("Train is still running.");
      continue;
    }
    if ((System.currentTimeMillis() - wtime) > 60000) {
      System.out.println("Waited long enough looks like train has stopped.");
      break;
    }
  }
  m_kafkaConfig.stop();
  consumersLatch.await();
  consumersLatch2.await();
  System.out.println("Seen Rows: " + consumedRows.get() + " Expected: "+ expectedRows);
  if (consumedRows.get() < expectedRows) {
    System.out.println("ERROR: Exported row count does not match consumed rows.");
    testGood.set(false);
  }
  m_kafkaConfig=null;
}
