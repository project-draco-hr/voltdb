{
  List<String> lineList=null;
  while ((m_config.limitrows-- > 0)) {
    if (m_errored) {
      break;
    }
    try {
      if (m_listReader.getLineNumber() == 0) {
        m_totalLineCount.set(m_config.skip);
      }
 else {
        m_totalLineCount.set(m_listReader.getLineNumber());
      }
      long st=System.nanoTime();
      lineList=m_listReader.read();
      long end=System.nanoTime();
      m_parsingTime+=(end - st);
      if (lineList == null) {
        if (m_totalLineCount.get() > m_listReader.getLineNumber()) {
          m_totalLineCount.set(m_listReader.getLineNumber());
        }
        break;
      }
      m_totalRowCount.incrementAndGet();
      String[] correctedLine=lineList.toArray(new String[0]);
      String lineCheckResult;
      if ((lineCheckResult=checkparams_trimspace(correctedLine,m_columnCnt)) != null) {
        String[] info={lineList.toString(),lineCheckResult};
        if (synchronizeErrorInfo(m_totalLineCount.get() + 1,info)) {
          m_errored=true;
        }
        continue;
      }
      CSVLineWithMetaData lineData=new CSVLineWithMetaData(correctedLine,lineList,m_listReader.getLineNumber());
      int partitionId=0;
      if (!CSVPartitionProcessor.m_isMP && !m_config.useSuppliedProcedure) {
        partitionId=TheHashinator.getPartitionForParameter(m_partitionColumnType.getValue(),(Object)lineData.correctedLine[m_partitionedColumnIndex]);
      }
      BlockingQueue<CSVLineWithMetaData> q=processorQueues.get(partitionId);
      q.offer(lineData);
    }
 catch (    SuperCsvException e) {
      e.printStackTrace();
      String[] info={e.getMessage(),""};
      if (synchronizeErrorInfo(m_totalLineCount.get() + 1,info)) {
        break;
      }
    }
catch (    IOException ioex) {
      ioex.printStackTrace();
      break;
    }
  }
  if (m_errorInfo.size() >= m_config.maxerrors) {
    m_log.info("The number of Failure row data exceeds " + m_config.maxerrors);
  }
  try {
    m_listReader.close();
  }
 catch (  IOException ex) {
    m_log.error("Error cloging Reader: " + ex);
  }
 finally {
    for (    BlockingQueue<CSVLineWithMetaData> q : processorQueues.values()) {
      try {
        q.put(m_endOfData);
      }
 catch (      InterruptedException ex) {
        m_log.error("Failed to add endOfData for Partition Processor. " + ex);
      }
    }
    m_log.info("Rows Queued by Reader: " + m_totalRowCount.get());
  }
  try {
    m_log.info("Waiting for partition processors to finish.");
    m_processor_cdl.await();
    m_log.info("Partition Processors Done.");
  }
 catch (  InterruptedException ex) {
    ;
  }
}
