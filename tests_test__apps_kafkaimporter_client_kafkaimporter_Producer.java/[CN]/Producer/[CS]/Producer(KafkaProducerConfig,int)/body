{
  this.config=config;
  m_topic=config.topic;
  m_servers=config.brokers;
  m_rate=config.producerrate;
  m_cycletime=config.cycletime;
  if (config.compression.equals("all"))   m_compression=KafkaProducerConfig.compression_types.split(" ")[topicnum % 4];
 else   m_compression=config.compression;
  log.info("Topic " + topicnum + " compression: "+ m_compression);
  m_pausetime=(int)(config.pausetime * Math.random());
  m_rows=config.totalrows;
  long possiblecycles=m_rows / (m_rate * m_cycletime);
  m_cycles=(possiblecycles > config.cycles) ? possiblecycles : config.cycles;
  m_rangemin=m_rows * topicnum;
  m_topic=m_topic + topicnum;
  m_json_obj=new JSONObject();
  Properties props=new Properties();
  props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,m_servers);
  props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,m_compression);
  props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());
  props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());
  props.put(ProducerConfig.ACKS_CONFIG,"all");
  m_producer=new KafkaProducer<String,String>(props);
  log.info("Instantiate Producer: " + m_topic + ", "+ m_servers+ ", "+ m_rate+ ", "+ m_cycletime+ ", "+ m_pausetime+ ", "+ m_rows);
}
